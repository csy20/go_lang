# Go Concurrency Basics: Goroutines & Channels

## Table of Contents
1. [Understanding Concurrency vs Parallelism](#understanding-concurrency-vs-parallelism)
2. [Goroutines: Lightweight Threads](#goroutines-lightweight-threads)
3. [Channels: Safe Communication](#channels-safe-communication)
4. [Synchronization Patterns](#synchronization-patterns)
5. [Real-World Examples](#real-world-examples)

---

## Understanding Concurrency vs Parallelism

Before diving into Go's concurrency model, it's crucial to understand the difference:

### Concurrency vs Parallelism

```
CONCURRENCY (One person juggling multiple tasks)
Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
Task A: â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ
Task B:     â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ
Task C:         â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ
```

```
PARALLELISM (Multiple people doing tasks simultaneously)
Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
Core 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Core 2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Core 3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Core 4: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

**Concurrency**: Dealing with multiple things at once (design)
**Parallelism**: Doing multiple things at once (execution)

Go's motto: **"Don't communicate by sharing memory; share memory by communicating"**

---

## Goroutines: Lightweight Threads

### What Are Goroutines?

Goroutines are **lightweight threads** managed by the Go runtime. They're not OS threads but rather multiplexed onto OS threads by the Go scheduler.

#### Key Characteristics:
- **Extremely lightweight**: Start with ~2KB stack (vs ~2MB for OS threads)
- **Cheap to create**: You can have thousands or millions
- **Managed by Go runtime**: Automatic scheduling and multiplexing
- **Cooperative scheduling**: Yield at function calls, channel operations, etc.

### Creating Goroutines

#### Basic Syntax
```go
go functionName(arguments)
go func() {
    // anonymous function
}()
```

#### Your First Goroutine
```go
package main

import (
    "fmt"
    "time"
)

func sayHello(name string) {
    for i := 0; i < 3; i++ {
        fmt.Printf("Hello from %s (%d)\n", name, i)
        time.Sleep(100 * time.Millisecond)
    }
}

func main() {
    fmt.Println("Starting program")
    
    // Start a goroutine
    go sayHello("Goroutine")
    
    // This runs in the main goroutine
    sayHello("Main")
    
    fmt.Println("Program ended")
}

// Output might be:
// Starting program
// Hello from Main (0)
// Hello from Goroutine (0)
// Hello from Main (1)
// Hello from Goroutine (1)
// Hello from Main (2)
// Hello from Goroutine (2)
// Program ended
```

#### Important: Main Goroutine Termination
```go
func main() {
    go sayHello("Goroutine")
    
    // If main goroutine ends, ALL goroutines are terminated!
    // This program might not print anything from the goroutine
    fmt.Println("Main finished")
}
```

To fix this, we need synchronization:
```go
func main() {
    go sayHello("Goroutine")
    
    // Wait for goroutine to finish (naive approach)
    time.Sleep(1 * time.Second)
    
    fmt.Println("Main finished")
}
```

### Multiple Goroutines
```go
func worker(id int) {
    for i := 0; i < 3; i++ {
        fmt.Printf("Worker %d: doing task %d\n", id, i)
        time.Sleep(time.Duration(100+id*50) * time.Millisecond)
    }
}

func main() {
    fmt.Println("Starting workers")
    
    // Start multiple goroutines
    for i := 1; i <= 3; i++ {
        go worker(i)
    }
    
    // Wait for all to complete
    time.Sleep(2 * time.Second)
    fmt.Println("All workers done")
}

// Output (order may vary):
// Starting workers
// Worker 1: doing task 0
// Worker 2: doing task 0
// Worker 3: doing task 0
// Worker 1: doing task 1
// Worker 2: doing task 1
// Worker 1: doing task 2
// Worker 3: doing task 1
// Worker 2: doing task 2
// Worker 3: doing task 2
// All workers done
```

### Anonymous Goroutines
```go
func main() {
    // Anonymous goroutine with closure
    message := "Hello from closure"
    
    go func() {
        fmt.Println(message) // Captures variable from outer scope
    }()
    
    // Goroutine with parameters (safer than closure for loop variables)
    for i := 0; i < 3; i++ {
        go func(id int) {
            fmt.Printf("Goroutine %d\n", id)
        }(i) // Pass i as parameter
    }
    
    time.Sleep(100 * time.Millisecond)
}
```

### Common Goroutine Pitfall: Loop Variables
```go
// WRONG: All goroutines might print the same value
func wrongWay() {
    for i := 0; i < 3; i++ {
        go func() {
            fmt.Printf("Wrong: %d\n", i) // Captures variable by reference!
        }()
    }
    time.Sleep(100 * time.Millisecond)
    // Might print: Wrong: 3, Wrong: 3, Wrong: 3
}

// CORRECT: Pass value as parameter
func correctWay() {
    for i := 0; i < 3; i++ {
        go func(id int) {
            fmt.Printf("Correct: %d\n", id) // Uses parameter value
        }(i)
    }
    time.Sleep(100 * time.Millisecond)
    // Prints: Correct: 0, Correct: 1, Correct: 2 (order may vary)
}
```

---

## Channels: Safe Communication

### What Are Channels?

Channels are Go's way of allowing goroutines to communicate safely. They're **typed conduits** through which you can send and receive values.

**Think of channels as pipes**: One goroutine puts data in one end, another goroutine takes data out the other end.

### Channel Basics

#### Creating Channels
```go
// Create a channel
ch := make(chan int)        // Unbuffered channel
ch2 := make(chan string, 5) // Buffered channel with capacity 5

// Channel operations
ch <- 42        // Send value 42 to channel
value := <-ch   // Receive value from channel
```

#### Unbuffered Channels (Synchronous)
```go
func main() {
    ch := make(chan string)
    
    // Start a goroutine that sends data
    go func() {
        fmt.Println("Goroutine: About to send")
        ch <- "Hello from goroutine"
        fmt.Println("Goroutine: Sent data")
    }()
    
    fmt.Println("Main: About to receive")
    message := <-ch
    fmt.Println("Main: Received:", message)
}

// Output:
// Main: About to receive
// Goroutine: About to send
// Goroutine: Sent data
// Main: Received: Hello from goroutine
```

**Key Point**: Unbuffered channels are **synchronous**. The sender blocks until a receiver is ready, and vice versa.

#### Buffered Channels (Asynchronous)
```go
func main() {
    ch := make(chan string, 2) // Buffer size 2
    
    // These sends don't block because buffer has space
    ch <- "First"
    ch <- "Second"
    
    fmt.Println("Sent two messages")
    
    // This would block because buffer is full
    // ch <- "Third" // Would deadlock!
    
    // Receive messages
    fmt.Println("Received:", <-ch) // "First"
    fmt.Println("Received:", <-ch) // "Second"
}
```

### Channel Directions

You can restrict channels to be send-only or receive-only:

```go
// Send-only channel
func sender(ch chan<- string) {
    ch <- "Hello"
    // value := <-ch // Compile error! Can't receive on send-only channel
}

// Receive-only channel
func receiver(ch <-chan string) {
    message := <-ch
    fmt.Println("Received:", message)
    // ch <- "Hi" // Compile error! Can't send on receive-only channel
}

func main() {
    ch := make(chan string)
    
    go sender(ch)   // Converts bidirectional to send-only
    receiver(ch)    // Converts bidirectional to receive-only
}
```

### Closing Channels

```go
func main() {
    ch := make(chan int, 3)
    
    // Send some values
    ch <- 1
    ch <- 2
    ch <- 3
    
    // Close the channel
    close(ch)
    
    // Can still receive from closed channel
    for value := range ch {
        fmt.Println("Received:", value)
    }
    
    // Receiving from closed channel returns zero value and false
    value, ok := <-ch
    fmt.Printf("Value: %d, OK: %t\n", value, ok) // Value: 0, OK: false
}
```

#### When to Close Channels

```go
func producer(ch chan<- int) {
    defer close(ch) // Close when function exits
    
    for i := 1; i <= 5; i++ {
        ch <- i
        time.Sleep(100 * time.Millisecond)
    }
}

func consumer(ch <-chan int) {
    // Range automatically exits when channel is closed
    for value := range ch {
        fmt.Printf("Consumed: %d\n", value)
    }
    fmt.Println("Consumer finished")
}

func main() {
    ch := make(chan int)
    
    go producer(ch)
    consumer(ch) // Runs in main goroutine
}
```

### Channel Select Statement

The `select` statement lets you wait on multiple channel operations:

```go
func main() {
    ch1 := make(chan string)
    ch2 := make(chan string)
    
    // Goroutine 1
    go func() {
        time.Sleep(100 * time.Millisecond)
        ch1 <- "Message from ch1"
    }()
    
    // Goroutine 2
    go func() {
        time.Sleep(200 * time.Millisecond)
        ch2 <- "Message from ch2"
    }()
    
    // Select waits for the first available channel
    select {
    case msg1 := <-ch1:
        fmt.Println("Received from ch1:", msg1)
    case msg2 := <-ch2:
        fmt.Println("Received from ch2:", msg2)
    }
}
```

#### Select with Default Case
```go
func main() {
    ch := make(chan string)
    
    select {
    case message := <-ch:
        fmt.Println("Received:", message)
    default:
        fmt.Println("No message available")
    }
    // Output: No message available
}
```

#### Select with Timeout
```go
func main() {
    ch := make(chan string)
    
    select {
    case message := <-ch:
        fmt.Println("Received:", message)
    case <-time.After(2 * time.Second):
        fmt.Println("Timeout! No message received")
    }
    // Output (after 2 seconds): Timeout! No message received
}
```

---

## Synchronization Patterns

### 1. Wait Groups

The `sync.WaitGroup` is used to wait for multiple goroutines to complete:

```go
import (
    "fmt"
    "sync"
    "time"
)

func worker(id int, wg *sync.WaitGroup) {
    defer wg.Done() // Signal that this worker is done
    
    fmt.Printf("Worker %d starting\n", id)
    time.Sleep(time.Duration(id) * 100 * time.Millisecond)
    fmt.Printf("Worker %d done\n", id)
}

func main() {
    var wg sync.WaitGroup
    
    for i := 1; i <= 3; i++ {
        wg.Add(1) // Increment counter
        go worker(i, &wg)
    }
    
    wg.Wait() // Wait for all workers to call Done()
    fmt.Println("All workers completed")
}
```

### 2. Fan-Out/Fan-In Pattern

**Fan-out**: Distribute work to multiple goroutines
**Fan-in**: Collect results from multiple goroutines

```go
// Fan-out: Generate work
func generateNumbers(max int) <-chan int {
    ch := make(chan int)
    go func() {
        defer close(ch)
        for i := 1; i <= max; i++ {
            ch <- i
        }
    }()
    return ch
}

// Worker function
func square(numbers <-chan int) <-chan int {
    result := make(chan int)
    go func() {
        defer close(result)
        for num := range numbers {
            result <- num * num
        }
    }()
    return result
}

// Fan-in: Merge multiple channels
func merge(channels ...<-chan int) <-chan int {
    merged := make(chan int)
    
    var wg sync.WaitGroup
    
    // Start a goroutine for each input channel
    for _, ch := range channels {
        wg.Add(1)
        go func(c <-chan int) {
            defer wg.Done()
            for value := range c {
                merged <- value
            }
        }(ch)
    }
    
    // Close merged channel when all input channels are done
    go func() {
        wg.Wait()
        close(merged)
    }()
    
    return merged
}

func main() {
    // Generate numbers
    numbers := generateNumbers(10)
    
    // Fan-out: Create multiple workers
    worker1 := square(numbers)
    worker2 := square(numbers)
    worker3 := square(numbers)
    
    // Fan-in: Merge results
    results := merge(worker1, worker2, worker3)
    
    // Collect all results
    for result := range results {
        fmt.Printf("Result: %d\n", result)
    }
}
```

### 3. Worker Pool Pattern

```go
type Job struct {
    ID   int
    Data string
}

type Result struct {
    JobID int
    Value string
}

func worker(id int, jobs <-chan Job, results chan<- Result) {
    for job := range jobs {
        fmt.Printf("Worker %d processing job %d\n", id, job.ID)
        
        // Simulate work
        time.Sleep(100 * time.Millisecond)
        
        // Send result
        results <- Result{
            JobID: job.ID,
            Value: fmt.Sprintf("Processed %s", job.Data),
        }
    }
}

func main() {
    const numWorkers = 3
    const numJobs = 10
    
    // Create channels
    jobs := make(chan Job, numJobs)
    results := make(chan Result, numJobs)
    
    // Start workers
    for i := 1; i <= numWorkers; i++ {
        go worker(i, jobs, results)
    }
    
    // Send jobs
    for i := 1; i <= numJobs; i++ {
        jobs <- Job{
            ID:   i,
            Data: fmt.Sprintf("task-%d", i),
        }
    }
    close(jobs)
    
    // Collect results
    for i := 0; i < numJobs; i++ {
        result := <-results
        fmt.Printf("Result for job %d: %s\n", result.JobID, result.Value)
    }
}
```

### 4. Pipeline Pattern

```go
// Stage 1: Generate numbers
func numbers(max int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for i := 1; i <= max; i++ {
            out <- i
        }
    }()
    return out
}

// Stage 2: Square numbers
func squares(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for num := range in {
            out <- num * num
        }
    }()
    return out
}

// Stage 3: Filter even numbers
func evens(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for num := range in {
            if num%2 == 0 {
                out <- num
            }
        }
    }()
    return out
}

func main() {
    // Create pipeline: numbers -> squares -> evens
    pipeline := evens(squares(numbers(10)))
    
    // Consume results
    for result := range pipeline {
        fmt.Printf("Even square: %d\n", result)
    }
}
// Output: Even square: 4, Even square: 16, Even square: 36, Even square: 64, Even square: 100
```

---

## Real-World Examples

### Example 1: Web Scraper

```go
package main

import (
    "fmt"
    "io"
    "net/http"
    "sync"
    "time"
)

type ScrapeResult struct {
    URL    string
    Status int
    Error  error
    Size   int
}

func scrapeURL(url string, results chan<- ScrapeResult) {
    defer func() {
        if r := recover(); r != nil {
            results <- ScrapeResult{
                URL:   url,
                Error: fmt.Errorf("panic: %v", r),
            }
        }
    }()
    
    resp, err := http.Get(url)
    if err != nil {
        results <- ScrapeResult{
            URL:   url,
            Error: err,
        }
        return
    }
    defer resp.Body.Close()
    
    body, err := io.ReadAll(resp.Body)
    if err != nil {
        results <- ScrapeResult{
            URL:    url,
            Status: resp.StatusCode,
            Error:  err,
        }
        return
    }
    
    results <- ScrapeResult{
        URL:    url,
        Status: resp.StatusCode,
        Size:   len(body),
    }
}

func main() {
    urls := []string{
        "https://golang.org",
        "https://github.com",
        "https://stackoverflow.com",
        "https://reddit.com",
        "https://news.ycombinator.com",
    }
    
    results := make(chan ScrapeResult, len(urls))
    
    // Start scraping goroutines
    for _, url := range urls {
        go scrapeURL(url, results)
    }
    
    // Collect results with timeout
    timeout := time.After(10 * time.Second)
    collected := 0
    
    for collected < len(urls) {
        select {
        case result := <-results:
            if result.Error != nil {
                fmt.Printf("âŒ %s: %v\n", result.URL, result.Error)
            } else {
                fmt.Printf("âœ… %s: Status %d, Size %d bytes\n", 
                    result.URL, result.Status, result.Size)
            }
            collected++
        case <-timeout:
            fmt.Printf("â° Timeout! Only got %d/%d results\n", collected, len(urls))
            return
        }
    }
    
    fmt.Printf("ðŸŽ‰ Scraped %d URLs successfully\n", collected)
}
```

### Example 2: Rate-Limited API Client

```go
package main

import (
    "fmt"
    "time"
)

type APIRequest struct {
    ID   int
    Data string
}

type APIResponse struct {
    RequestID int
    Result    string
    Error     error
}

// Rate limiter using buffered channel
type RateLimiter struct {
    tokens chan struct{}
    ticker *time.Ticker
}

func NewRateLimiter(rps int) *RateLimiter {
    rl := &RateLimiter{
        tokens: make(chan struct{}, rps),
        ticker: time.NewTicker(time.Second / time.Duration(rps)),
    }
    
    // Fill initial tokens
    for i := 0; i < rps; i++ {
        rl.tokens <- struct{}{}
    }
    
    // Refill tokens
    go func() {
        for range rl.ticker.C {
            select {
            case rl.tokens <- struct{}{}:
            default:
                // Channel full, skip
            }
        }
    }()
    
    return rl
}

func (rl *RateLimiter) Wait() {
    <-rl.tokens
}

func (rl *RateLimiter) Stop() {
    rl.ticker.Stop()
}

// API client
type APIClient struct {
    rateLimiter *RateLimiter
}

func NewAPIClient(rps int) *APIClient {
    return &APIClient{
        rateLimiter: NewRateLimiter(rps),
    }
}

func (api *APIClient) ProcessRequest(req APIRequest) APIResponse {
    // Wait for rate limit token
    api.rateLimiter.Wait()
    
    // Simulate API call
    fmt.Printf("Processing request %d: %s\n", req.ID, req.Data)
    time.Sleep(100 * time.Millisecond) // Simulate network delay
    
    return APIResponse{
        RequestID: req.ID,
        Result:    fmt.Sprintf("Processed: %s", req.Data),
    }
}

func (api *APIClient) ProcessRequestsAsync(requests []APIRequest) <-chan APIResponse {
    responses := make(chan APIResponse, len(requests))
    
    var wg sync.WaitGroup
    
    for _, req := range requests {
        wg.Add(1)
        go func(r APIRequest) {
            defer wg.Done()
            response := api.ProcessRequest(r)
            responses <- response
        }(req)
    }
    
    go func() {
        wg.Wait()
        close(responses)
    }()
    
    return responses
}

func main() {
    // Create API client with 2 requests per second rate limit
    client := NewAPIClient(2)
    defer client.rateLimiter.Stop()
    
    // Create requests
    requests := make([]APIRequest, 10)
    for i := 0; i < 10; i++ {
        requests[i] = APIRequest{
            ID:   i + 1,
            Data: fmt.Sprintf("task-%d", i+1),
        }
    }
    
    fmt.Printf("Starting to process %d requests (rate limited to 2/sec)\n", len(requests))
    start := time.Now()
    
    // Process requests asynchronously
    responses := client.ProcessRequestsAsync(requests)
    
    // Collect responses
    count := 0
    for response := range responses {
        count++
        fmt.Printf("Response %d: %s\n", response.RequestID, response.Result)
    }
    
    duration := time.Since(start)
    fmt.Printf("Processed %d requests in %v\n", count, duration)
}
```

### Example 3: Producer-Consumer with Buffering

```go
package main

import (
    "fmt"
    "math/rand"
    "sync"
    "time"
)

type Task struct {
    ID       int
    Priority int
    Data     string
}

type Worker struct {
    ID   int
    quit chan bool
}

func NewWorker(id int) *Worker {
    return &Worker{
        ID:   id,
        quit: make(chan bool),
    }
}

func (w *Worker) Start(tasks <-chan Task, results chan<- string, wg *sync.WaitGroup) {
    defer wg.Done()
    
    for {
        select {
        case task := <-tasks:
            // Process task
            processingTime := time.Duration(rand.Intn(500)+100) * time.Millisecond
            fmt.Printf("Worker %d processing task %d (priority %d)\n", 
                w.ID, task.ID, task.Priority)
            
            time.Sleep(processingTime)
            
            result := fmt.Sprintf("Worker %d completed task %d: %s", 
                w.ID, task.ID, task.Data)
            results <- result
            
        case <-w.quit:
            fmt.Printf("Worker %d stopping\n", w.ID)
            return
        }
    }
}

func (w *Worker) Stop() {
    close(w.quit)
}

// Task producer
func producer(tasks chan<- Task, numTasks int) {
    defer close(tasks)
    
    for i := 1; i <= numTasks; i++ {
        task := Task{
            ID:       i,
            Priority: rand.Intn(5) + 1,
            Data:     fmt.Sprintf("data-%d", i),
        }
        
        fmt.Printf("Producing task %d\n", task.ID)
        tasks <- task
        
        // Simulate varying production rate
        time.Sleep(time.Duration(rand.Intn(200)+50) * time.Millisecond)
    }
    
    fmt.Println("Producer finished")
}

func main() {
    const numWorkers = 3
    const numTasks = 15
    const bufferSize = 5
    
    // Create channels
    tasks := make(chan Task, bufferSize)
    results := make(chan string, bufferSize)
    
    // Create and start workers
    var wg sync.WaitGroup
    workers := make([]*Worker, numWorkers)
    
    for i := 0; i < numWorkers; i++ {
        workers[i] = NewWorker(i + 1)
        wg.Add(1)
        go workers[i].Start(tasks, results, &wg)
    }
    
    // Start producer
    go producer(tasks, numTasks)
    
    // Collect results
    go func() {
        wg.Wait()
        close(results)
    }()
    
    // Print results as they come
    resultCount := 0
    for result := range results {
        resultCount++
        fmt.Printf("ðŸ“‹ Result %d: %s\n", resultCount, result)
    }
    
    // Stop all workers
    for _, worker := range workers {
        worker.Stop()
    }
    
    fmt.Printf("âœ… Completed processing %d tasks\n", resultCount)
}
```

## Key Takeaways

### Goroutines
1. **Extremely lightweight** - you can have thousands
2. **Managed by Go runtime** - automatic scheduling
3. **Start with `go`** - simple syntax
4. **Main goroutine termination kills all others**
5. **Be careful with loop variables** - pass as parameters

### Channels
1. **Typed conduits** for safe communication
2. **Unbuffered channels are synchronous** - sender blocks until receiver ready
3. **Buffered channels are asynchronous** - up to buffer capacity
4. **Close channels to signal completion**
5. **Use `select` for multiple channel operations**

### Best Practices
1. **"Don't communicate by sharing memory; share memory by communicating"**
2. **Use channels for communication, mutexes for protecting shared state**
3. **Close channels in the sender, not receiver**
4. **Use `sync.WaitGroup` to wait for multiple goroutines**
5. **Handle goroutine panics appropriately**
6. **Consider context.Context for cancellation**

### Common Patterns
- **Fan-out/Fan-in**: Distribute work and collect results
- **Worker pools**: Fixed number of workers processing jobs
- **Pipelines**: Chain of processing stages
- **Rate limiting**: Control request frequency
- **Producer-consumer**: Decouple production and consumption

Go's concurrency model makes it easy to write efficient, concurrent programs. The combination of goroutines and channels provides a powerful and safe way to handle concurrent operations without the complexity of traditional threading models.
